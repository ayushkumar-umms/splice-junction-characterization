{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all annotated splice junctions based on GTF File (maxEnt.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file contains the function to extract all the splice junctions from a GTF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sys import argv\n",
    "import time\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and Intital setup of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to this function is the GTF file. We first get all the transcripts in the GTF file and for each of them iterate through to find all the exons associated with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_spl_junctions(df):\n",
    "    gtf = df\n",
    "    gtf  = gtf[~gtf['transcript_id'].isin([np.nan])]\n",
    "    transcripts = set(gtf['transcript_id'].tolist())\n",
    "    gtf = gtf.set_index('transcript_id')\n",
    "    gtf = gtf[(gtf['feature'].isin(['exon']))]\n",
    "    gtf = gtf[['seqname', 'source', 'feature', 'start', 'end','strand','exon_id']]\n",
    "    junctions = set()\n",
    "    start = time.process_time()\n",
    "    ind = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each transcript, order the exons based on start site. After ordering each transcript, we measure the distance between each exon to make sure it is graeter than 1. (Can't have a splice junction if the exons are right next to each other). We then take the coordinates in betweeen each exon and define that as the splice junction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transcripts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8c9ba277c9fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtran\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranscripts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mextract_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtran\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#extract_trans = gtf[np.in1d(gtf['transcript_id'].values, [tran])]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#exons_of_transcript = extract_trans[np.in1d(extract_trans['feature'].values, 'exon')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#exons_of_transcript = extract_trans[extract_trans['feature']=='exon']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transcripts' is not defined"
     ]
    }
   ],
   "source": [
    "    for tran in transcripts:\n",
    "        extract_trans = gtf.loc[gtf.index.isin([tran])]\n",
    "        #extract_trans = gtf[np.in1d(gtf['transcript_id'].values, [tran])]\n",
    "        #exons_of_transcript = extract_trans[np.in1d(extract_trans['feature'].values, 'exon')]\n",
    "        #exons_of_transcript = extract_trans[extract_trans['feature']=='exon']\n",
    "        exon_list = extract_trans[['seqname', 'start','end','strand']].to_numpy().tolist()\n",
    "        exon_list.sort()\n",
    "        tmp_exons = [exon_list[0]]\n",
    "        for i in range(1, len(exon_list)):\n",
    "            if exon_list[i][1] - tmp_exons[-1][2] < 1:\n",
    "                tmp_exons[-1][2] = exon_list[i][1]\n",
    "            else:\n",
    "                tmp_exons.append(exon_list[i])\n",
    "        for i in range(1,len(tmp_exons)):\n",
    "            junctions.add((tmp_exons[0][0],tmp_exons[i-1][2]+1,tmp_exons[i][1]-1, tmp_exons[0][3]))\n",
    "        if ind % 10000 == 0:\n",
    "            print(time.process_time() - start, '%i of %i' % (ind,len(transcripts)))\n",
    "        ind+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output all the junctions as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.DataFrame(junctions, columns = ['seqname', 'start','end','strand'])\n",
    "    convert_type = {'seqname': str, 'strand': str}\n",
    "    df.astype(convert_type)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
